{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good tutorial for elasticsearch python http://nitin-panwar.github.io/Elasticsearch-tutorial-for-beginners-using-Python/\n",
    "#https://elasticsearch-py.readthedocs.io/en/master/\n",
    "#http://snowsyn.net/2016/10/25/having-fun-with-elasticsearch-and-python/\n",
    "#https://marcobonzanini.com/2015/02/02/how-to-query-elasticsearch-with-python/\n",
    "#https://www.elastic.co/guide/en/elasticsearch/guide/current/routing-value.html for the report how distributed indexing works\n",
    "#http://xpo6.com/using-elasticsearch-analyzer-remove-stop-words-from-text/\n",
    "#https://www.elastic.co/guide/en/elasticsearch/guide/current/data-in-data-out.html  every field has a dedicated inverted index for fast retrieval.\n",
    "#https://dzone.com/articles/23-useful-elasticsearch-example-queries\n",
    "\n",
    "from elasticsearch import Elasticsearch \n",
    "# Connect to the elastic cluster\n",
    "es=Elasticsearch([{'host':'localhost','port':9200}])\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'nitin', 'last_name': 'panwar', 'age': 27, 'about': 'Love to play cricket', 'interests': ['sports', 'music']}\n"
     ]
    }
   ],
   "source": [
    "e1={\n",
    "    \"first_name\":\"nitin\",\n",
    "    \"last_name\":\"panwar\",\n",
    "    \"age\": 27,\n",
    "    \"about\": \"Love to play cricket\",\n",
    "    \"interests\": ['sports','music'],\n",
    "}\n",
    "print(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.kibana_1': {'aliases': {'.kibana': {}}},\n",
       " 'megacorp': {'aliases': {}},\n",
       " 'reeds': {'aliases': {}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.get_alias(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='job', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'es' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bb389eb21f17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'megacorp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'employee'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'es' is not defined"
     ]
    }
   ],
   "source": [
    "res = es.index(index='megacorp',doc_type='employee',id=1,body=e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's insert some more documents\n",
    "e2={\n",
    "    \"first_name\" :  \"Jane\",\n",
    "    \"last_name\" :   \"Smith\",\n",
    "    \"age\" :         32,\n",
    "    \"about\" :       \"I like to collect rock albums\",\n",
    "    \"interests\":  [ \"music\" ]\n",
    "}\n",
    "e3={\n",
    "    \"first_name\" :  \"Douglas\",\n",
    "    \"last_name\" :   \"Fir\",\n",
    "    \"age\" :         35,\n",
    "    \"about\":        \"I like to build cabinets\",\n",
    "    \"interests\":  [ \"forestry\" ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=es.index(index='megacorp',doc_type='employee',id=2,body=e2)\n",
    "res=es.index(index='megacorp',doc_type='employee',id=3,body=e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'megacorp', '_type': 'employee', '_id': '3', '_version': 1, '_seq_no': 0, '_primary_term': 1, 'found': True, '_source': {'first_name': 'Douglas', 'last_name': 'Fir', 'age': 35, 'about': 'I like to build cabinets', 'interests': ['forestry']}}\n"
     ]
    }
   ],
   "source": [
    "res=es.get(index='megacorp',doc_type='employee',id=3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Douglas', 'last_name': 'Fir', 'age': 35, 'about': 'I like to build cabinets', 'interests': ['forestry']}\n"
     ]
    }
   ],
   "source": [
    "print(res['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res=es.delete(index='megacorp',doc_type='employee',id=1)\n",
    "#res=es.delete(index='megacorp',doc_type='employee',id=2)\n",
    "#res=es.delete(index='megacorp',doc_type='employee',id=3)\n",
    "\n",
    "#job = {\n",
    "#    \"title\": \"technology returner programme\", \"company\": \"nomura\", \"description\": \"nomura diversity critical success harness value perspectives employees different work family experience backgrounds bring firm past experience invaluable us nomura technology division pleased launching first returner programme looking individuals taken career break 18months much longer looking return workplace successful candidates receive significant training support help transition new role world technology fast moving excellent opportunities find fulfilling role also provides flexibility need roles available 4 5 day week basis nomura financial services group integrated global network spanning 30 countries head offices asia connecting markets east west service needs individuals institutions corporates governments four business divisions retail asset management wholesale global markets investment banking merchant banking offer technology returner programme based london office designed experienced professionals ready build previous skills experience want embrace new opportunities ahead paid programme commences april 29th finishes 19th july 2019. end 3-month programme participants invited apply number open roles offer number type roles available outlined programme \\u2019 guarantee permanent role ensure developed valuable skills exposure wide-reaching influential network involvement high impact projects global financial services company looking returners join us previous experience business analysts project managers developers specific opportunities offer include strategic projects manager cto office software engineer business analyst team leader security consultant project manager hybrid project manager/it business analyst programme open women men career break least 18 months minimum number 5 years professional experience need able work city based london office duration programme eligible work uk april 2019 july 2019. opportunities available 4 5 days week basis pending preference supported goal support back workplace get taste career global investment bank support line manager coach buddy also employee networks join build network across firm prior 12 weeks provided pre-commencement coaching training day inclusivity one day induction organisation three personal coaching sessions delivered inclusivity \\u2019 specialist coach relevant technical training role remuneration benefits opportunity salary aligned market rates also access programme nomura services emergency childcare adult dependent care fitness centre onsite restaurant onsite gp nurse dental practice apply help application process questions hesitate contact us submit c.v. cover letter online tuesday 5th march latest please ensure c.v. shows career break least 18 months immediately preceding date application programme help us get know better include cover letter 've taken break work include motivates want return please place cover letter document cv shortlisted inclusivity touch organise first interview please click 'apply button redirected website\", \"location\": \"london\", \"URL\": \"https://www.technojobs.co.uk/job/2620662/technology-returner-programme/\"}, {\"title\": \"mobile developer in test javascript appium mocha chai\", \"company\": \"client server\", \"description\": \"mobile developer test javascript appium mocha chai city based financial software house provide range web based trading single-dealer platforms seeking mobile developer test experience testing mobile front end applications six month contract city office mobile developer test responsible developing automated test cases test frameworks new functionality within jenkins environment include functional non-functional testing using variety open source tools libraries 'll collaborate ux designers product owners define implement unit acceptance integration performance tests relaxed city based offices table tennis football casual dress code flexible working requirements *experience testing mobile applications appium *experience javascript testing frameworks including mocha chai *experience working jenkins *experience software tester developer test good appreciation test automation *passionate code quality advocate clean code principles *excellent analysis problem solving skills meticulous attention detail *nice mobile testing experience react react native apply call confidential discussion developer test contract opportunity mobile developer test javascript appium mocha chai rate \\u00a3400 \\u00a3450 p/day location london city term 6 months start immediate asap\", \"location\": \"london\", \"URL\": \"https://www.technojobs.co.uk/job/2624214/mobile-developer-in-test-javascript-appium-mocha-chai/\"\n",
    "#    }\n",
    "\n",
    "#res=es.index(index='technojobs',doc_type='jobs',id=1,body=job)\n",
    "#print(res)\n",
    "#es.indices.delete(index='job', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'job'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index='job', body={\n",
    "   'settings' : {\n",
    "         'index' : {\n",
    "              'number_of_shards':5\n",
    "         },\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"filter_stemmer\": {\n",
    "          \"type\": \"stemmer\",\n",
    "          \"language\": \"english\"\n",
    "        },\n",
    "            \"stopwordEn\": {\n",
    "            \"type\":       \"stop\",\n",
    "            \"stopwords\":  \"_english_\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"tags_analyzer\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"filter\": [\n",
    "            \"standard\",\n",
    "            \"lowercase\",\n",
    "            \"filter_stemmer\"\n",
    "          ],\n",
    "          \"tokenizer\": \"standard\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "   }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "## Delete index before building a new one, otherwise it will stack\n",
    "es.indices.delete(index='job', ignore=[400, 404])\n",
    "\n",
    "with open('all_jobs.json', 'r') as f:\n",
    "    technojobs_dict = json.load(f)\n",
    "    #count = 0\n",
    "    for technojob in technojobs_dict:\n",
    "        #count+=1\n",
    "#         my_id = technojob.pop('URL', None)\n",
    "        es.index(index='job', doc_type='job', body=json.dumps(technojob))\n",
    "        #if count >= 10:\n",
    "        #    break\n",
    "    \n",
    "#for technojob in technojobs_dict:\n",
    "#    print(technojob['title'])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technojobs_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchFunction(feature, search):\n",
    "    res = es.search(index=\"job\", doc_type=\"job\", body={\"query\": {\"match\": {feature: search}}})\n",
    "    print(\"%d documents found\" % res['hits']['total'])\n",
    "    for doc in res['hits']['hits']:\n",
    "        print(\"%s) %s\" % (doc['_id'], doc['_source'][feature]))\n",
    "        \n",
    "def searchFunctionAllFeatures(search):\n",
    "    res = es.search(index=\"job\", doc_type=\"job\", body={\"query\": {\"multi_match\" : {\n",
    "            \"query\" : search,\n",
    "            \"fields\": [\"title^3\", \"description\",\"location\",\"URL\"]#makes the title three times more important\n",
    "        }}})\n",
    "    print(\"%d documents found\" % res['hits']['total'])\n",
    "    for doc in res['hits']['hits']:\n",
    "        print(\"%s) %s\" % (doc['_id'], doc['_source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 documents found\n",
      "tcA0fWkBX9rBgXuLKY0b) \n",
      "            Data Scientist        \n",
      "IcA0fWkBX9rBgXuLEIeR) \n",
      "            Data Scientist         \n",
      "ZcA0fWkBX9rBgXuLOpJj) \n",
      "            Data Scientist         \n",
      "x8A0fWkBX9rBgXuLWZqq) \n",
      "            Data Scientist        \n",
      "xcA0fWkBX9rBgXuLc6G_) \n",
      "            Data Scientist        \n",
      "5ApZmmkBO93G78ZJoCQU) data scientist\n",
      "kMA0fWkBX9rBgXuLJYwH) \n",
      "            Data Scientist        \n",
      "o8A0fWkBX9rBgXuLA4Ow) \n",
      "            Data Scientist        \n",
      "YMA0fWkBX9rBgXuLap-5) \n",
      "            Data Scientist         \n",
      "-QpZmmkBO93G78ZJkB8L) data scientist\n"
     ]
    }
   ],
   "source": [
    "searchFunction(\"title\",\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 documents found\n",
      "w2aSkGkB484-OV2z91VE) {'title': '\\n            Hadoop Developer        ', 'company': '\\n                        Computer Futures                    ', 'description': ['\\n            Start: latest 1st of May 2019', '\\r\\n', '\\r\\nEnd: 31st of March 2020 (extension possible)', '\\r\\n', '\\r\\nLocation: Stockholm', '\\r\\n', '\\r\\nWorkload: 100%', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nYour tasks mean that you primarily work with the Hadoop platform and SQL server both strategically and operationally to provide the business with data for report tools and reports. Your role includes proposing technical solutions and proactively improving the platform, but also acting as a sounding board for various stakeholders in the business.', '\\r\\n', '\\r\\nYour background', '\\r\\n', '\\r\\nWe see that you have a solid IT background with an academic degree or equivalent experience acquired in another way. You have at least 3 years of experience with BI solutions. Merit is the experience of Hadoop and the experience of agile working methods.', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nRequirements', '\\r\\n', '\\r\\n * -Academic degree', '\\r\\n * -Most three years of experience with BI solutions', '\\r\\n * -Experience of Hadoop', '\\r\\n * Java, Python, R, SQL, Scala', '\\r\\n * HDFS, YARN, Hive, Spark, Nifi or Kafka', '\\r\\n * Building and optimizing large data flows including the integration', '\\r\\n * working with unstructured data sets, manipulating, processing and extracting value from large amounts of data', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nPlease send your CV and hourly rate or give me a call.', '\\r\\n', '\\r\\nLooking forward to have a further discussion.', '\\r\\n', '\\r\\nRegards,', '\\r\\n', '\\r\\nJana                    '], 'location': '\\n                        Stockholm                    ', 'salary': '\\n                        Negotiable                    ', 'date_listed': '\\n                        22nd February                    '}\n",
      "22aSkGkB484-OV2z91Xh) {'title': '\\n            Hadoop Data Engineer        ', 'company': '\\n                        Computer Futures                    ', 'description': ['\\n            Who They Are:', '\\r\\n', '\\r\\nYou will working for a market leading Data consultancy that helps customers manage multiple data types from countless varied sources. You will be helping with solutions for Data Lake, Machine Learning & Cyber Security.', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nWhat you will be doing:', '\\r\\n', \"\\r\\nYou will have to work closely with Data Scientists to help design methods for collecting and integrating a variety of Data which will then be used in predictive analytics or in other data science uses. You will have to apply big data technologies such as Hadoop, Spark or Streams and also have NoSQL data management experience with large, multi-structured Data sets. You will work closely with customer's businesses\", '\\r\\n', '\\r\\nWhat you need:', '\\r\\n', \"\\r\\n * Master's degree or equivalent in Computer science, computer engineering, computer applications or any related field\", '\\r\\n * Have 2 years of experience in: Linux, Hadoop, Oracle, Informatica and Teradata', '\\r\\n * Used other tools & technologies such as Kafka, Cassandra, Storm, Spark and streams with NoSQL', '\\r\\n', '\\r\\nIf you are looking for a new position and think that you have the above skills needed, please apply with your CV today.', '\\n', '\\nTo find out more about Computer Futures please visit www.computerfutures.com', '\\n', '\\n ', '\\n', '\\nComputer Futures, a trading division of SThree Partnership LLP is acting as an Employment Agency in relation to this vacancy | Registered office | 1st Floor, 75 King William Street, London, EC4N 7BE, United Kingdom | Partnership Number | OC387148 England and Wales                    '], 'location': '\\n                        London                    ', 'salary': '\\n                        £70,000 - £95,000                    ', 'date_listed': '\\n                        1st March                    '}\n",
      "U2aSkGkB484-OV2zKjtT) {'title': '\\n            Full Stack Developer / Python / Spark / Hadoop         ', 'company': '\\n                        Spring Group Plc                    ', 'description': ['\\n            ', '\\r\\nMy client is currently recruiting for a Full Stack Software Developer with experience in Python, Spark and Hadoop for a 6 - 12 month contract based in the city of London.', '\\r\\n', '\\r\\nResponsibilities:', '\\r\\n*Requirement is for a Python spark developer who will help with data on boarding using python and spark. ', '\\r\\n*The ideal candidate is adept at using large data sets and transform and enrich the same.', '\\r\\n', '\\r\\nEssential Skills:', '\\r\\n*Hands on experience with Python and Spark', '\\r\\n*Hands on experience with Hadoop using spark', '\\r\\n*Ability to perform end to end application development, testing and deployment', '\\r\\n*Experience in developing RESTful web services', '\\r\\n*Oracle database working experience with good RDBMS concepts and query tuning exposure', '\\r\\n*Ability to work with global team and mentor junior developers as needed Functional', '\\r\\n*Experience in trade Surveillance domain and trade model development is a plus.', '\\r\\n', '\\r\\nLocation : London,  United Kingdom', '\\r\\n', '\\r\\nIf this role is of interest please can you submit a copy of your latest cv ', '\\n', '\\nSpring acts as an employment agency for permanent recruitment and an employment business for the supply of temporary workers. The Spring Group UK is an Equal Opportunities Employer.', '\\r\\n', '\\r\\nBy applying for this role your details will be submitted to Spring. Our Candidate Privacy Information Statement explains how we will use your information - please copy and paste the following link in to your browser: www.spring.com/candidate-privacy-information-statement                    '], 'location': '\\n                        City of London                    ', 'salary': '\\n                        Negotiable                    ', 'date_listed': '\\n                        26th February                    '}\n",
      "XWaSkGkB484-OV2zYEGs) {'title': '\\n            Big Data Developer (Hadoop) - Java - SQL - Agile/Scrum - Security Cleared        ', 'company': '\\n                        SQCP                    ', 'description': ['\\n            ', 'Big Data Developer (Hadoop) required for a leading global security company with offices in London. Mu client has an immediate opportunity for an experienced big data engineer/ developer in building data pipelines and processing high volumes of data. Successful candidates will work within exciting and prominent programmes and be asked to support the team in Scrum/Agile development. Engineers will perform design of mission critical products, whilst supporting the pursuit of new business.', '\\r\\n', '\\xa0', '\\r\\n', 'You will hold the following key responsibilities:', '\\r\\n', '** Will design, develop, test and integrate quality software', '\\r\\n', '** Has experience of building Hadoop data pipelines in production environments', '\\r\\n', '** Has a strong understanding of data structures and algorithms relevant to processing high volumes of data', '\\r\\n', '** Has an understanding of data governance, security and audit requirements', '\\r\\n', '\\xa0', '\\r\\n', 'Key Criteria Required:', '\\r\\n', 'Experience in software development using:', '\\r\\n', '** Java and use of object oriented design', '\\r\\n', '** Spark (Batch & Streaming)', '\\r\\n', '** SQL', '\\r\\n', '** HDFS', '\\r\\n', '** Soir', '\\r\\n', '** Scala', '\\r\\n', '** Experience or knowledge of Agile / Scrum methodologies', '\\r\\n', '** Applicants must be able to hold and maintain UK Government clearances', '\\r\\n', '\\xa0', '\\r\\n', 'We would also love it if you have:', '\\r\\n', '** Knowledge or experience various open source products, for example: Apache Foundation products', '\\r\\n', '\\xa0', '\\r\\n', 'Experience with:', '\\r\\n', '** NiFi', '\\r\\n', '** Python', '\\r\\n', '** Lucene index/ query strategies', '\\r\\n', '\\xa0', '\\r\\n', 'Production experience of:', '\\r\\n', '** NLP/ Image processing', '\\r\\n', '** Hbase', '\\r\\n', '** Kafka', '\\r\\n', '** Experience of using Atlassian Jira/ IBM RTC suite, or similar product lifecycle software packages', '\\r\\n', '**Experience of UK Government working practices', '\\r\\n', '\\xa0', '\\r\\n', 'Candidates must hold an active DV security clearance/', '\\r\\n', '\\xa0', '\\r\\n', 'Please note your CV will not be submitted for this or any other role without your prior approval.\\xa0', '\\r\\n', 'SQ Computer Personnel Limited acts as both an Employment Agency and Employment Business.', '                    '], 'location': '\\n                        LONDON                    ', 'salary': '\\n                        Neg                    ', 'date_listed': '\\n                        26th February                    '}\n",
      "xWaSkGkB484-OV2z1FB0) {'title': '\\n            Informatica BDM Consultant         ', 'company': '\\n                        Progressive                    ', 'description': ['\\n            Informatica BDM Consultant- Financial Services- Melbourne CBD', '\\r\\n', '\\r\\nWe are seeking a Informatica BDM Consultant to join a fast growing Financial services firm based in the heart of the city.', '\\r\\n', '\\r\\n Description ', '\\r\\n', '\\r\\n * Project experience with ETL tools such as Informatica on BIGdata ecosystem.', '\\r\\n * Good working knowledge of ecosystem works in BIG data. Ability to develop custom components in Informatica Big Data Edition.', '\\r\\n * Involve in gathering business requirements for the data warehouse as well as business intelligence reports to be used by management.', '\\r\\n * Implement Informatica implement mappings for extracting data from DWH to Data Lake.', '\\r\\n * Design & development of BDM mappings in Hive mode for large volume of INSERT/UPDATE.', '\\r\\n * Work on pushing existing ETL Logic to Hadoop cluster using Informatica BDM Tool.', '\\r\\n * Create BDM parameter sets, and parameter files for daily & delta loads.', '\\r\\n * Leveraged Informatica to load data from oracles to HDFS & vice versa.', '\\r\\n * Proven understanding with Hadoop, Hive, Pig & Hbase.', '\\r\\n', '\\r\\nThe requirements of the Informatica BDM Consultant', '\\r\\n', '\\r\\n * Experience developing Informatica mappings on AWS.', '\\r\\n * Informatica Blaze engine and benchmark against SPark or other big data processing frameworks.', '\\r\\n * Experience using Informatica command-line tools such as PMCMD.', '\\r\\n * Experience with Hadoop ecosystem technologies such as HIve, Hbase, etc.', '\\r\\n * Experience working with RDBMS. ', '\\r\\n * Research based mindset', '\\r\\n * The ideal Data Engineer will have a clear route of progression from the start and will be a key decision maker for the company.', '\\r\\n', '\\r\\nPlease contact Paulina for any further feedback.', '\\n', '\\nTo find out more about Progressive Recruitment please visit our website. ', '\\n', '\\n ', '\\n', '\\nAward Winner for:', '\\n', '\\nBest Medium Recruitment Company of the Year by Recruitment International 2018', '\\n', '\\nTraining & Development Initiative of the Year by Recruitment International 2018                    '], 'location': '\\n                        Melbourne                    ', 'salary': '\\n                        £384 - £414                    ', 'date_listed': '\\n                        7th March                    '}\n",
      "L2aRkGkB484-OV2zqC10) {'title': '\\n            Java Developer - Big Data, Help Predict the Future        ', 'company': '\\n                        Understanding Recruitment                    ', 'description': ['\\n            Java Developer - Big Data, Help Predict the Future', '\\r\\n', \"\\r\\nWe are looking for an outstanding Java Developer to develop/design software projects that impact millions of people on a daily basis. As the Java Developer you'll be joining our tech hub in Central Nottingham, engineering a world-class product using a selection of big data technology. \", '\\r\\n ', '\\r\\n We are looking for a Java Developer with the following: ', '\\r\\n ', '\\r\\n * Strong Java development background ', '\\r\\n * Desire to learn and work with Big Data Tech - Hadoop, Spark, HBase, Hive, Impala,', '\\r\\n * Outstanding communication skills ', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nA fantastic opportunity for the Java Developer to join the market leader in their industry, work with some very intelligent Developers using a range of the bleeding-edge tech. You will help us to create a platform that will predict future global events with technology such as Hadoop, Spark, Hive, Impala, HBase, & Scala. ', '\\r\\n', \"\\r\\nWe are looking for passionate technologists who know which technology excites them and why. There's the opportunity to work in an environment that allows you as the Java Developer to demonstrate your full potential. We encourage bright ideas and give our employees the autonomy to do so. Fantastic opportunities for career progression are available once established both nationally & internationally. \", '\\r\\n ', '\\r\\n Our Tech Includes: Java, Hadoop, Spark, Hive, Impala, HBase, Scala, MapReduce, Java Developer, Agile + many more ', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nApply now for immediate consideration!', '\\r\\n', '\\r\\nUnderstanding Recruitment is acting as an employment agency for this vacancy                    '], 'location': '\\n                        Nottingham                    ', 'salary': '\\n                        £50,000 - £55,000                    ', 'date_listed': '\\n                        10th February                    '}\n",
      "imaSkGkB484-OV2zETjo) {'title': '\\n            Java Developer - Predictive Analytics        ', 'company': '\\n                        Understanding Recruitment                    ', 'description': ['\\n            Java Developer - Predictive Analytics', '\\r\\n', \"\\r\\nWe are looking for an outstanding Java Developer to develop/design software projects that impact millions of people on a daily basis. As the Java Developer you'll be joining our tech hub in Central Nottingham, engineering a world-class product using a selection of big data technology. \", '\\r\\n ', '\\r\\n We are looking for a Java Developer with the following: ', '\\r\\n ', '\\r\\n * Strong Java development background ', '\\r\\n * Desire to learn and work with Big Data Tech - Hadoop, Spark, HBase, Hive, Impala,', '\\r\\n * Outstanding communication skills ', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nA fantastic opportunity for the Java Developer to join the market leader in their industry, work with some very intelligent Developers using a range of the bleeding-edge tech. You will help us to create a platform that will predict future global events with technology such as Hadoop, Spark, Hive, Impala, HBase, & Scala. ', '\\r\\n', \"\\r\\nWe are looking for passionate technologists who know which technology excites them and why. There's the opportunity to work in an environment that allows you as the Java Developer to demonstrate your full potential. We encourage bright ideas and give our employees the autonomy to do so. Fantastic opportunities for career progression are available once established both nationally & internationally. \", '\\r\\n ', '\\r\\n Our Tech Includes: Java, Hadoop, Spark, Hive, Impala, HBase, Scala, MapReduce, Java Developer, Agile + many more ', '\\r\\n', '\\r\\n ', '\\r\\n', '\\r\\nApply now for immediate consideration!', '\\r\\n', '\\r\\nUnderstanding Recruitment is acting as an employment agency for this vacancy                    '], 'location': '\\n                        Nottingham                    ', 'salary': '\\n                        £45,000 - £55,000                    ', 'date_listed': '\\n                        24th February                    '}\n",
      "UmaRkGkB484-OV2z9TV4) {'title': '\\n            Senior Software Engineer Java Big Data         ', 'company': '\\n                        Client Server                    ', 'description': [\"\\n            Senior Software Engineer / Java Developer (data privacy data sql hadoop). Help solve one of society's most urgent issues around personal data privacy and protection, working alongside extremely talented Java software and Data Science professionals. \", '\\r\\n', \"\\r\\nJoining a collaborative Agile team, as a Senior Software Engineer you'll combine state of the art technologies with leading-edge algorithms to understand and effectively tackle hard data security and data anonymisation problems. You'll be joining a team of first class software engineers that care deeply about the quality and maintainability of code, working on complex and interesting problems in an environment that encourages knowledge sharing and continual improvement. You'll be encouraged to innovate and keep up to date with emerging technologies; utilising Big Data technologies such as Spark, Hadoop and GraphLab.\", '\\r\\n', \"\\r\\nYou'll be based in cool, start-up offices with a modern and spacious environment and a friendly team atmosphere. \", '\\r\\n', '\\r\\nRequirements:', '\\r\\n*Strong Java development experience including multi-threading and concurrent programming', '\\r\\n*Full lifecycle development experience of a software product', '\\r\\n*Good knowledge of test automation ', '\\r\\n*Familiar with SQL and RDBMS technology ', '\\r\\n*Enjoy statistics and maths, intrigued by topics such as privacy-preserving data mining, differential privacy and homomorphic encryption', '\\r\\n*Collaborative team player who enjoys mentoring as well as learning', '\\r\\n*Degree educated, Computer Science preferred', '\\r\\n*Highly desirable: Spark, Hadoop, GraphLab, AWS or other cloud platform, Python, distributed algorithm design', '\\r\\n', '\\r\\nAs a Senior Software Engineer / Java Developer you will earn a highly competitive salary (to £100k) plus benefits.', '\\r\\n', '\\r\\nApply now or call for a confidential discussion about this Senior Software Engineer / Java Developer opportunity.', '\\r\\n                    '], 'location': '\\n                        London                    ', 'salary': '\\n                        £85,000 - £100,000                    ', 'date_listed': '\\n                        15th February                    '}\n",
      "8GaSkGkB484-OV2zgkW2) {'title': '\\n            DevOps Engineer        ', 'company': '\\n                        Real Staffing                    ', 'description': ['\\n            DevOps Engineer', '\\r\\n', '\\r\\nA leading utility client are looking for multiple DevOps engineer (s) to work in a growing team to support the innovative projects across the business.', '\\r\\n', '\\r\\nYou will have extensive DevOps experience on AWS. They are looking to build a new AWS infrastructure, automate their workflow and data processes.', '\\r\\n', '\\r\\nHaving previous experience working across AWS, architecture, security and big data platforms such as Hadoop will be a distinct advantage.', '\\r\\n', '\\r\\nExperience building and developing tools, TDD, BDD and continuous integration is also a benefit.', '\\r\\n', '\\r\\nThe role is looking to automate the development, testing and deployment process to ensure the AWS platform is fit for purpose.', '\\r\\n', '\\r\\nKnowledge Require-', '\\r\\n', '\\r\\n * AWS', '\\r\\n * Jenkins, Ansible, Play Docker.', '\\r\\n * Automation experience.', '\\r\\n * Hadoop, Spark, EMR', '\\r\\n * Python', '\\r\\n', '\\r\\nPlease apply with an updated CV and successful candidates will be contacted direct.', '\\n', '\\nTo find out more about Real please visit www.realstaffing.com', '\\n', '\\nReal Staffing, a trading division of SThree Partnership LLP is acting as an Employment Business in relation to this vacancy| Registered office | 1st Floor, 75 King William Street, London, EC4N 7BE, United Kingdom | Partnership Number | OC387148 England and Wales                    '], 'location': '\\n                        South East England                    ', 'salary': '\\n                        Contract                    ', 'date_listed': '\\n                        19th February                    '}\n",
      "z2aSkGkB484-OV2z91WQ) {'title': '\\n            Lead Data Engineer         ', 'company': '\\n                        Client Server                    ', 'description': ['\\n            Lead Data Engineer / Data Scientist (Spark Hadoop R SAS SQL Scala Python). FinTech start-up that works with high profile financial services and government organisations to provide data science services and complex software solutions to combat financial fraud is seeking a Senior Data Engineer to lead a small but growing team. ', '\\r\\n', '\\r\\nAs a Lead Data Engineer you will work with clients to solve business problems in the area of fraud, compliance and financial crime. Responsibilities will include eliciting and documenting solutions requirements; understanding patterns of criminal behaviour and designing systems to detect and investigate them. ', \"\\r\\nYou'll manage, transform and cleanse high volume data, performing advanced analytics to identify trends and automate analysis to proactively alert on high risk activity on an ongoing basis. Working closely with the development team you will be using leading open source data science tools such as Spark, Hadoop, and Lucence and will also gain exposure to Python and Scala to collaborate on scalability issues involving massive amounts of data and produce components for advanced analytics, matching, search and visualisation on big data. \", '\\r\\n', \"\\r\\nYou'll be based in London close to a mainline station near the City; you'll be working with a small, motivated, collaborative team of software, data and finance experts.\", '\\r\\n', '\\r\\nRequirements:', '\\r\\n*Excellent technical skills including expert knowledge of at least one analytical or big data package such as Spark, Hadoop, R, SAS, SQL', '\\r\\n*Good coding skills with Scala, Java and / or Python ', '\\r\\n*Some team leadership experience ', '\\r\\n*Excellent communication skills, client facing and presentation skills', '\\r\\n*Passion and enthusiasm for learning new technologies and techniques ', '\\r\\n*Degree educated, 2.1 or above', '\\r\\n*Ideally you will have a background in AML, KYC, screening, regulatory compliance or fraud', '\\r\\n', '\\r\\nAs a Lead Data Engineer / Data Scientist you will earn a competitive salary (to £100k) plus benefits.', '\\r\\n', '\\r\\nApply now or call for a confidential discussion about this Lead Data Engineer / Data Scientist opportunity.                    '], 'location': '\\n                        London                    ', 'salary': '\\n                        £85,000 - £100,000                    ', 'date_listed': '\\n                        15th February                    '}\n"
     ]
    }
   ],
   "source": [
    "searchFunctionAllFeatures(\"hadoop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
